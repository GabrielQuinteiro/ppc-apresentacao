{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xAqa2-MLETm"
      },
      "source": [
        "# Integrantes\n",
        "\n",
        "- Gabriel de Carvalho Barros - 1698558  \n",
        "- Henrique Melo Alves Martins - 1982661  \n",
        "- João Victor da Silva - 6296342  \n",
        "- Leticia Silverio - 5361635  \n",
        "- Vitor Roggeri Cavicchiolli - 4687234  \n",
        "- Rennys Rodrigues Cardoso - 3639077  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBcda_8PHlai",
        "outputId": "5a90b474-0001-47d6-f58c-848bfe5ff601"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\\n\""
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nimport zipfile\\n\\nwith zipfile.ZipFile(\\'dataset_00_sem_virg.zip\\', \\'r\\') as zip_ref:\\n    zip_ref.extractall()\\nprint(\"Arquivo extraído com sucesso.\"\\n'"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('dataset_00_sem_virg.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "print(\"Arquivo extraído com sucesso.\"\n",
        "''' "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOFUJomnf2_6"
      },
      "source": [
        "# Arquivos de Sistema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7pD8q1Jf4_s",
        "outputId": "e71bfd1a-b149-4849-f8ed-615b0f0a29ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting sistema.hpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile sistema.hpp\n",
        "\n",
        "#ifndef SISTEMA_HPP\n",
        "#define SISTEMA_HPP\n",
        "\n",
        "#include <string>\n",
        "#include <sys/stat.h>\n",
        "#ifdef _WIN32\n",
        "#include <windows.h>\n",
        "#include <psapi.h>\n",
        "#include <tchar.h>\n",
        "#else\n",
        "#include <sys/sysinfo.h>\n",
        "#include <fstream>\n",
        "#endif\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "#define MB (1024 * 1024)\n",
        "\n",
        "inline string extrair_nome_arquivo(const string& caminho_completo) {\n",
        "    size_t pos = caminho_completo.find_last_of(\"/\\\\\");\n",
        "    if (pos == string::npos) return caminho_completo;\n",
        "    return caminho_completo.substr(pos + 1);\n",
        "}\n",
        "\n",
        "inline size_t get_pico_uso_memoria_mb() {\n",
        "#ifdef _WIN32\n",
        "    PROCESS_MEMORY_COUNTERS info;\n",
        "    GetProcessMemoryInfo(GetCurrentProcess(), &info, sizeof(info));\n",
        "    return info.PeakWorkingSetSize / (1024 * 1024);\n",
        "#else\n",
        "    ifstream status(\"/proc/self/status\");\n",
        "    string linha;\n",
        "    while (getline(status, linha)) {\n",
        "        if (linha.find(\"VmHWM:\") == 0) {\n",
        "            size_t kb;\n",
        "            sscanf(linha.c_str(), \"VmHWM: %lu kB\", &kb);\n",
        "            return kb / 1024;\n",
        "        }\n",
        "    }\n",
        "    return 0;\n",
        "#endif\n",
        "}\n",
        "\n",
        "inline size_t get_memoria_total_mb() {\n",
        "#ifdef _WIN32\n",
        "    MEMORYSTATUSEX status;\n",
        "    status.dwLength = sizeof(status);\n",
        "    GlobalMemoryStatusEx(&status);\n",
        "    return static_cast<size_t>(status.ullTotalPhys / MB);\n",
        "#else\n",
        "    struct sysinfo info;\n",
        "    if (sysinfo(&info) != 0) return 1024;\n",
        "    return info.totalram * info.mem_unit / MB;\n",
        "#endif\n",
        "}\n",
        "\n",
        "inline size_t get_memoria_disponivel_mb() {\n",
        "#ifdef _WIN32\n",
        "    MEMORYSTATUSEX status;\n",
        "    status.dwLength = sizeof(status);\n",
        "    GlobalMemoryStatusEx(&status);\n",
        "    return static_cast<size_t>(status.ullAvailPhys / MB);\n",
        "#else\n",
        "    struct sysinfo info;\n",
        "    if (sysinfo(&info) != 0) return 1024;\n",
        "    return info.freeram * info.mem_unit / MB;\n",
        "#endif\n",
        "}\n",
        "\n",
        "inline size_t get_tamanho_arquivo_mb(const std::string& caminho) {\n",
        "#ifdef _WIN32\n",
        "    WIN32_FILE_ATTRIBUTE_DATA fileInfo;\n",
        "    if (!GetFileAttributesExA(caminho.c_str(), GetFileExInfoStandard, &fileInfo)) {\n",
        "        return 0;\n",
        "    }\n",
        "\n",
        "    ULARGE_INTEGER size;\n",
        "    size.HighPart = fileInfo.nFileSizeHigh;\n",
        "    size.LowPart = fileInfo.nFileSizeLow;\n",
        "    return static_cast<size_t>(size.QuadPart / MB);\n",
        "#else\n",
        "    struct stat stat_buf;\n",
        "    if (stat(caminho.c_str(), &stat_buf) != 0) return 0;\n",
        "    return static_cast<size_t>(stat_buf.st_size / MB);\n",
        "#endif\n",
        "}\n",
        "\n",
        "inline string get_nome_cpu() {\n",
        "#ifdef _WIN32\n",
        "    HKEY hKey;\n",
        "    if (RegOpenKeyEx(HKEY_LOCAL_MACHINE,\n",
        "        TEXT(\"HARDWARE\\\\DESCRIPTION\\\\System\\\\CentralProcessor\\\\0\"),\n",
        "        0, KEY_READ, &hKey) == ERROR_SUCCESS) {\n",
        "\n",
        "        TCHAR nome_cpu[256];\n",
        "        DWORD tamanho = sizeof(nome_cpu);\n",
        "        if (RegQueryValueEx(hKey, TEXT(\"ProcessorNameString\"), NULL, NULL, (LPBYTE)nome_cpu, &tamanho) == ERROR_SUCCESS) {\n",
        "            RegCloseKey(hKey);\n",
        "            return string(nome_cpu, nome_cpu + _tcslen(nome_cpu));\n",
        "        }\n",
        "        RegCloseKey(hKey);\n",
        "    }\n",
        "    return \"Desconhecido\";\n",
        "#else\n",
        "    ifstream cpuinfo(\"/proc/cpuinfo\");\n",
        "    string linha;\n",
        "    while (getline(cpuinfo, linha)) {\n",
        "        if (linha.find(\"model name\") != string::npos) {\n",
        "            return linha.substr(linha.find(\":\") + 2);\n",
        "        }\n",
        "    }\n",
        "    return \"Desconhecido\";\n",
        "#endif\n",
        "}\n",
        "\n",
        "#endif // SISTEMA_HPP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d2DX1W3giqo"
      },
      "source": [
        "# Arquivos de Leitura"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRuAe40-gkfq",
        "outputId": "8259ca69-48db-4c4b-d504-0708d2bce11b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting leitura.hpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile leitura.hpp\n",
        "\n",
        "#ifndef LEITURA_HPP\n",
        "#define LEITURA_HPP\n",
        "\n",
        "#include <vector>\n",
        "#include <string>\n",
        "#include <fstream>\n",
        "#include <sstream>\n",
        "#include <iostream>\n",
        "\n",
        "using namespace std;\n",
        "using Linha = vector<string>;\n",
        "\n",
        "#define MB (1024 * 1024)\n",
        "\n",
        "// remove espaços, \\r, \\n e \\t do início e fim da string\n",
        "static inline string trim(const string& s) {\n",
        "    size_t start = s.find_first_not_of(\" \\t\\r\\n\");\n",
        "    if (start == string::npos) return \"\";\n",
        "    size_t end = s.find_last_not_of(\" \\t\\r\\n\");\n",
        "    return s.substr(start, end - start + 1);\n",
        "}\n",
        "\n",
        "// detecta se a string representa um numero (int/float)\n",
        "inline bool eh_numero(const string& valor) {\n",
        "    string val = trim(valor);\n",
        "    if (val.empty()) return false;\n",
        "\n",
        "    // remove aspas externas, se houver\n",
        "    if (val.front() == '\"' && val.back() == '\"' && val.length() > 1)\n",
        "        val = val.substr(1, val.length() - 2);\n",
        "\n",
        "    bool ponto = false;\n",
        "    size_t i = 0;\n",
        "    if (val[0] == '-' || val[0] == '+') i++;\n",
        "\n",
        "    for (; i < val.size(); ++i) {\n",
        "        unsigned char c = static_cast<unsigned char>(val[i]);\n",
        "        if (!isdigit(c)) {\n",
        "            if (c == '.' && !ponto) {\n",
        "                ponto = true;\n",
        "            } else {\n",
        "                return false;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    return true;\n",
        "}\n",
        "\n",
        "inline void detectar_colunas_categoricas(const vector<string>& nomeColunas,\n",
        "                                         const vector<vector<string>>& amostras,\n",
        "                                         vector<int>& indicesAlvo) {\n",
        "\n",
        "    size_t numLinhas = min<size_t>(amostras.size(), 5);\n",
        "\n",
        "    for (size_t col = 0; col < nomeColunas.size(); ++col) {\n",
        "        bool temAlfanumerico = false;\n",
        "\n",
        "        // se em alguma das linhas existir valor “não vazio” e não-numérico, é categórica\n",
        "        for (size_t lin = 0; lin < numLinhas; ++lin) {\n",
        "            const string& raw = amostras[lin][col];\n",
        "            string val = trim(raw);\n",
        "            if (!val.empty() && val != \"\\\"\\\"\" && !eh_numero(val)) {\n",
        "                temAlfanumerico = true;\n",
        "                break;\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if (temAlfanumerico) {\n",
        "            indicesAlvo.push_back(col);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "inline void ler_cabecalho_e_amostras(const string& caminho,\n",
        "                                     vector<string>& nomeColunas,\n",
        "                                     vector<Linha>& amostras,\n",
        "                                     int linhasAmostra = 5) {\n",
        "    ifstream arquivo(caminho);\n",
        "    if (!arquivo.is_open()) {\n",
        "        cerr << \"Nao foi possivel abrir o arquivo.\" << endl;\n",
        "        exit(1);\n",
        "    }\n",
        "\n",
        "    string cabecalho;\n",
        "    getline(arquivo, cabecalho);\n",
        "    stringstream ss(cabecalho);\n",
        "    string coluna;\n",
        "    while (getline(ss, coluna, ',')) {\n",
        "        nomeColunas.push_back(coluna);\n",
        "    }\n",
        "\n",
        "    string linha;\n",
        "    while (linhasAmostra-- > 0 && getline(arquivo, linha)) {\n",
        "        stringstream ssl(linha);\n",
        "        string valor;\n",
        "        Linha linhaDados;\n",
        "        while (getline(ssl, valor, ',')) {\n",
        "            linhaDados.push_back(valor);\n",
        "        }\n",
        "        amostras.push_back(linhaDados);\n",
        "    }\n",
        "    arquivo.close();\n",
        "}\n",
        "\n",
        "\n",
        "size_t calcular_tamanho_chunk_mb(size_t bytes_por_linha, size_t linhas_por_chunk) {\n",
        "    return (bytes_por_linha * linhas_por_chunk) / MB;\n",
        "}\n",
        "\n",
        "size_t calcular_linhas_por_chunk(size_t memoria_disponivel_mb, size_t media_bytes_por_linha = 200) {\n",
        "    size_t memoria_bytes = memoria_disponivel_mb * MB;\n",
        "    size_t memoria_para_uso = memoria_bytes / 25; // Usa 10% da RAM disponível\n",
        "    return memoria_para_uso / media_bytes_por_linha;\n",
        "}\n",
        "\n",
        "inline size_t calcular_bytes_por_linha_com_amostras(const vector<Linha>& amostras) {\n",
        "    if (amostras.empty()) return 200;\n",
        "    size_t total = 0;\n",
        "    for (const auto& linha : amostras) {\n",
        "        for (const auto& campo : linha) {\n",
        "            total += campo.size();\n",
        "        }\n",
        "        total += linha.size() - 1; // vírgulas\n",
        "    }\n",
        "    return total / amostras.size();\n",
        "}\n",
        "\n",
        "#endif // LEITURA_HPP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UflVx1PGhFXt"
      },
      "source": [
        "# Arquivos de Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26T6jFx6hKYV",
        "outputId": "ca2269d2-c650-47c2-fec6-70eb71e47991"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting benchmark.hpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile benchmark.hpp\n",
        "\n",
        "#ifndef BENCHMARK_HPP\n",
        "#define BENCHMARK_HPP\n",
        "\n",
        "#include <string>\n",
        "#include <vector>\n",
        "#include <fstream>\n",
        "#include <iostream>\n",
        "#include <iomanip>\n",
        "#include \"sistema.hpp\"\n",
        "#include \"leitura.hpp\"\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "struct BenchmarkInfo {\n",
        "    string nome_arquivo;\n",
        "    size_t tamanho_mb;\n",
        "    size_t ram_disponivel_mb;\n",
        "    size_t ram_total_mb;\n",
        "    size_t bytes_por_linha;\n",
        "    size_t linhas_por_chunk;\n",
        "    double tamanho_chunk_mb;\n",
        "    string cpu;\n",
        "    int num_threads;\n",
        "    int colunas_categoricas;\n",
        "    double tempo_execucao;\n",
        "};\n",
        "\n",
        "inline BenchmarkInfo coletar_info_benchmark(const string& caminho_dataset,\n",
        "                                            const vector<Linha>& amostras,\n",
        "                                            int colunas_categoricas,\n",
        "                                            int num_threads\n",
        "                                            ) {\n",
        "    BenchmarkInfo info;\n",
        "    info.nome_arquivo = extrair_nome_arquivo(caminho_dataset);\n",
        "    info.tamanho_mb = get_tamanho_arquivo_mb(caminho_dataset);\n",
        "    info.ram_disponivel_mb = get_memoria_disponivel_mb();\n",
        "    info.ram_total_mb = get_memoria_total_mb();\n",
        "    info.bytes_por_linha = calcular_bytes_por_linha_com_amostras(amostras);\n",
        "    info.linhas_por_chunk = calcular_linhas_por_chunk(info.ram_disponivel_mb, info.bytes_por_linha);\n",
        "    info.tamanho_chunk_mb = calcular_tamanho_chunk_mb(info.bytes_por_linha, info.linhas_por_chunk);\n",
        "    info.num_threads = num_threads;\n",
        "    info.colunas_categoricas = colunas_categoricas;\n",
        "    info.cpu = get_nome_cpu();\n",
        "    return info;\n",
        "}\n",
        "\n",
        "inline void exibir_info_benchmark(const BenchmarkInfo& info) {\n",
        "    cout << \"\\n===== INFOS =====\" << endl;\n",
        "    cout << \"Nome do arquivo: \" << info.nome_arquivo << endl;\n",
        "    cout << \"Tamanho do arquivo: \" << info.tamanho_mb << \" MB\" << endl;\n",
        "    cout << \"RAM disponivel: \" << info.ram_disponivel_mb << \" MB\" << endl;\n",
        "    cout << \"RAM total do sistema: \" << info.ram_total_mb << \" MB\" << endl;\n",
        "    cout << \"Bytes por linha (estimado): \" << info.bytes_por_linha << endl;\n",
        "    cout << \"Linhas por chunk: \" << info.linhas_por_chunk << endl;\n",
        "    cout << \"Tamnho por chunk: \" << info.tamanho_chunk_mb << \" MB\" << endl;\n",
        "\n",
        "    cout << \"Processador: \" << info.cpu << endl;\n",
        "    cout << \"Cores (threads): \" << info.num_threads << endl;\n",
        "    cout << \"Colunas categóricas detectadas: \" << info.colunas_categoricas << endl;\n",
        "    cout << \"======================\\n\" << endl;\n",
        "}\n",
        "\n",
        "inline string formatar_tempo(double segundos) {\n",
        "    int minutos = static_cast<int>(segundos) / 60;\n",
        "    int seg = static_cast<int>(segundos) % 60;\n",
        "    ostringstream oss;\n",
        "    oss << minutos << \"m \" << seg << \"s\";\n",
        "    return oss.str();\n",
        "}\n",
        "\n",
        "inline void salvar_info_benchmark_csv(const BenchmarkInfo& info, const string& caminho_saida) {\n",
        "    bool arquivo_existe = ifstream(caminho_saida).good();\n",
        "    ofstream arq(caminho_saida, ios::app);\n",
        "    if (!arq.is_open()) {\n",
        "        cerr << \"Erro ao salvar informacoes no CSV.\" << endl;\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    if (!arquivo_existe) {\n",
        "        arq << \"nome_arquivo,nome_cpu,num_threads,ram_total_mb,ram_disponivel_mb,tamanho_arq_mb,bytes_por_linha,linhas_por_chunk,tamanho_chunk_mb,total_col_categoricas,tempo_execucao_segundos,tempo_formatado\\n\";\n",
        "    }\n",
        "\n",
        "    arq << info.nome_arquivo << \",\"\n",
        "        << '\"' << info.cpu << '\"' << \",\"\n",
        "        << info.num_threads << \",\"\n",
        "        << info.ram_total_mb << \",\"\n",
        "        << info.ram_disponivel_mb << \",\"\n",
        "        << info.tamanho_mb << \",\"\n",
        "        << info.bytes_por_linha << \",\"\n",
        "        << info.linhas_por_chunk << \",\"\n",
        "        << fixed << setprecision(2) << info.tamanho_chunk_mb << \",\"\n",
        "        << info.colunas_categoricas << \",\"\n",
        "        << fixed << setprecision(2) << info.tempo_execucao << \",\"\n",
        "        << formatar_tempo(info.tempo_execucao) << \"\\n\";\n",
        "\n",
        "    arq.close();\n",
        "}\n",
        "\n",
        "#endif // BENCHMARK_HPP\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzK4J2RtrHkG"
      },
      "source": [
        "# Executar OMP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKgobAHoqujE",
        "outputId": "16b9b38a-d52b-45f8-ddd3-c32fff60e547"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting normalizador_omp.hpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile normalizador_omp.hpp\n",
        "\n",
        "#ifndef NORMALIZADOR_OMP_HPP\n",
        "#define NORMALIZADOR_OMP_HPP\n",
        "\n",
        "#include <vector>\n",
        "#include <string>\n",
        "#include <unordered_map>\n",
        "#include <unordered_set>\n",
        "#include <fstream>\n",
        "#include <sstream>\n",
        "#include <omp.h>\n",
        "#include <iostream>\n",
        "\n",
        "#include <queue>\n",
        "#include <map>\n",
        "#include <thread>\n",
        "#include <mutex>\n",
        "#include <condition_variable>\n",
        "#include <atomic>\n",
        "\n",
        "using namespace std;\n",
        "using Linha = vector<string>;\n",
        "\n",
        "inline void construir_mapas_codificacao_por_chunks(const string& caminho,\n",
        "                                                   const vector<string>& nomeColunas,\n",
        "                                                   const vector<int>& indicesAlvo,\n",
        "                                                   size_t linhas_por_chunk,\n",
        "                                                   unordered_map<string, unordered_map<string, int>>& mapas,\n",
        "                                                   unordered_map<string, int>& contadores) {\n",
        "    ifstream arquivo(caminho);\n",
        "    if (!arquivo.is_open()) {\n",
        "        cerr << \"Erro ao abrir o arquivo para processar chunks.\" << endl;\n",
        "        exit(1);\n",
        "    }\n",
        "\n",
        "    string cabecalho;\n",
        "    getline(arquivo, cabecalho); // descarta cabeçalho\n",
        "\n",
        "    string linha;\n",
        "    vector<Linha> chunk;\n",
        "\n",
        "    while (getline(arquivo, linha)) {\n",
        "        stringstream ss(linha);\n",
        "        string valor;\n",
        "        Linha linhaDados;\n",
        "        while (getline(ss, valor, ',')) {\n",
        "            linhaDados.push_back(valor);\n",
        "        }\n",
        "        chunk.push_back(linhaDados);\n",
        "\n",
        "        if (chunk.size() >= linhas_por_chunk) {\n",
        "            int num_threads = omp_get_max_threads();\n",
        "            vector<unordered_map<string, unordered_map<string, int>>> mapasLocais(num_threads);\n",
        "\n",
        "            #pragma omp parallel for schedule(dynamic)\n",
        "            for (int i = 0; i < indicesAlvo.size(); i++) {\n",
        "                int col = indicesAlvo[i];\n",
        "                string nomeCol = nomeColunas[col];\n",
        "                int tid = omp_get_thread_num();\n",
        "\n",
        "                for (const auto& linhaChunk : chunk) {\n",
        "                    if (col >= linhaChunk.size()) continue;\n",
        "                    string valor = linhaChunk[col];\n",
        "                    if (valor.empty()) continue;\n",
        "\n",
        "                    mapasLocais[tid][nomeCol][valor];\n",
        "                }\n",
        "            }\n",
        "\n",
        "            for (const auto& local : mapasLocais) {\n",
        "                for (const auto& [coluna, mapa] : local) {\n",
        "                    for (const auto& [valor, _] : mapa) {\n",
        "                        if (mapas[coluna].find(valor) == mapas[coluna].end()) {\n",
        "                            mapas[coluna][valor] = contadores[coluna]++;\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "            chunk.clear();\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (!chunk.empty()) {\n",
        "        int num_threads = omp_get_max_threads();\n",
        "        vector<unordered_map<string, unordered_map<string, int>>> mapasLocais(num_threads);\n",
        "\n",
        "        #pragma omp parallel for schedule(dynamic)\n",
        "        for (int i = 0; i < indicesAlvo.size(); i++) {\n",
        "            int col = indicesAlvo[i];\n",
        "            string nomeCol = nomeColunas[col];\n",
        "            int tid = omp_get_thread_num();\n",
        "\n",
        "            for (const auto& linhaChunk : chunk) {\n",
        "                if (col >= linhaChunk.size()) continue;\n",
        "                string valor = linhaChunk[col];\n",
        "                if (valor.empty()) continue;\n",
        "\n",
        "                mapasLocais[tid][nomeCol][valor];\n",
        "            }\n",
        "        }\n",
        "\n",
        "        for (const auto& local : mapasLocais) {\n",
        "            for (const auto& [coluna, mapa] : local) {\n",
        "                for (const auto& [valor, _] : mapa) {\n",
        "                    if (mapas[coluna].find(valor) == mapas[coluna].end()) {\n",
        "                        mapas[coluna][valor] = contadores[coluna]++;\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "\n",
        "    arquivo.close();\n",
        "}\n",
        "\n",
        "inline void gerar_arquivos_id_por_coluna(const unordered_map<string, unordered_map<string, int>>& mapas) {\n",
        "    #pragma omp parallel for schedule(dynamic)\n",
        "    for (int i = 0; i < mapas.size(); ++i) {\n",
        "        auto it = next(mapas.begin(), i);\n",
        "        const string& nomeCol = it->first;\n",
        "        const auto& mapa = it->second;\n",
        "\n",
        "        ofstream arquivo(\"ID_\" + nomeCol + \".csv\");\n",
        "        if (!arquivo.is_open()) {\n",
        "            #pragma omp critical\n",
        "            cerr << \"Erro ao criar arquivo ID_\" << nomeCol << \".csv\" << endl;\n",
        "            continue;\n",
        "        }\n",
        "\n",
        "        arquivo << \"COD,CONTEUDO\\n\";\n",
        "        for (const auto& [conteudo, cod] : mapa) {\n",
        "            arquivo << cod << \",\" << conteudo << \"\\n\";\n",
        "        }\n",
        "        arquivo.close();\n",
        "    }\n",
        "}\n",
        "\n",
        "inline vector<string> codificar_linhas_chunk(const vector<string>& chunk,\n",
        "                                      const vector<string>& nomeColunas,\n",
        "                                      const unordered_map<string, unordered_map<string, int>>& mapas) {\n",
        "    vector<string> linhasCodificadas(chunk.size());\n",
        "    #pragma omp parallel for\n",
        "    for (int i = 0; i < chunk.size(); i++) {\n",
        "        stringstream ss(chunk[i]);\n",
        "        string valor;\n",
        "        vector<string> campos;\n",
        "        while (getline(ss, valor, ',')) {\n",
        "            campos.push_back(valor);\n",
        "        }\n",
        "        stringstream codificada;\n",
        "        for (int j = 0; j < campos.size(); j++) {\n",
        "            const string& nomeCol = nomeColunas[j];\n",
        "            if (mapas.count(nomeCol)) {\n",
        "                codificada << mapas.at(nomeCol).at(campos[j]);\n",
        "            } else {\n",
        "                codificada << campos[j];\n",
        "            }\n",
        "            if (j < campos.size() - 1) codificada << \",\";\n",
        "        }\n",
        "        linhasCodificadas[i] = codificada.str();\n",
        "    }\n",
        "    return linhasCodificadas;\n",
        "}\n",
        "\n",
        "inline void gerar_dataset_codificado(const string& caminho,\n",
        "                                     const vector<string>& nomeColunas,\n",
        "                                     const vector<int>& indicesAlvo,\n",
        "                                     const unordered_map<string, unordered_map<string, int>>& mapas,\n",
        "                                     size_t linhas_por_chunk) {\n",
        "    ifstream entrada(caminho);\n",
        "    ofstream saida(\"dataset_codificado_omp.csv\");\n",
        "\n",
        "    if (!entrada.is_open() || !saida.is_open()) {\n",
        "        cerr << \"Erro ao abrir arquivos.\" << endl;\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    string cabecalho;\n",
        "    getline(entrada, cabecalho);\n",
        "    saida << cabecalho << \"\\n\";\n",
        "\n",
        "    queue<pair<size_t, vector<string>>> fila_chunks;\n",
        "    map<size_t, vector<string>> resultados;\n",
        "\n",
        "    mutex mtx_fila, mtx_resultado;\n",
        "    condition_variable cv_fila, cv_resultado;\n",
        "    atomic<bool> leitura_concluida{false};\n",
        "\n",
        "    size_t seq_id = 0;\n",
        "    const unsigned N_CONSUMIDORES = thread::hardware_concurrency();\n",
        "    vector<thread> consumidores;\n",
        "\n",
        "    // CONSUMIDORES\n",
        "    for (unsigned t = 0; t < N_CONSUMIDORES; ++t) {\n",
        "        consumidores.emplace_back([&]() {\n",
        "            while (true) {\n",
        "                pair<size_t, vector<string>> item;\n",
        "\n",
        "                {\n",
        "                    unique_lock<mutex> lock(mtx_fila);\n",
        "                    cv_fila.wait(lock, [&]() {\n",
        "                        return !fila_chunks.empty() || leitura_concluida;\n",
        "                    });\n",
        "\n",
        "                    if (!fila_chunks.empty()) {\n",
        "                        item = move(fila_chunks.front());\n",
        "                        fila_chunks.pop();\n",
        "                    } else if (leitura_concluida) {\n",
        "                        break;\n",
        "                    } else {\n",
        "                        continue;\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                auto codificadas = codificar_linhas_chunk(item.second, nomeColunas, mapas);\n",
        "\n",
        "                {\n",
        "                    lock_guard<mutex> lock(mtx_resultado);\n",
        "                    resultados[item.first] = move(codificadas);\n",
        "                }\n",
        "\n",
        "                cv_resultado.notify_one();\n",
        "            }\n",
        "        });\n",
        "    }\n",
        "\n",
        "    // ESCRITOR\n",
        "    thread escritor([&]() {\n",
        "        size_t proximo_seq = 0;\n",
        "\n",
        "        while (true) {\n",
        "            vector<string> linhas;\n",
        "            {\n",
        "                unique_lock<mutex> lock(mtx_resultado);\n",
        "                cv_resultado.wait(lock, [&]() {\n",
        "                    return resultados.count(proximo_seq) || (leitura_concluida && resultados.empty());\n",
        "                });\n",
        "\n",
        "                if (resultados.count(proximo_seq)) {\n",
        "                    linhas = move(resultados[proximo_seq]);\n",
        "                    resultados.erase(proximo_seq);\n",
        "                    ++proximo_seq;\n",
        "                } else if (leitura_concluida && resultados.empty()) {\n",
        "                    break;\n",
        "                } else {\n",
        "                    continue;\n",
        "                }\n",
        "            }\n",
        "\n",
        "            for (const auto& linha : linhas) {\n",
        "                saida << linha << \"\\n\";\n",
        "            }\n",
        "        }\n",
        "    });\n",
        "\n",
        "    // PRODUTOR (leitura do arquivo)\n",
        "    string linha;\n",
        "    vector<string> chunk;\n",
        "    while (getline(entrada, linha)) {\n",
        "        chunk.push_back(linha);\n",
        "        if (chunk.size() >= linhas_por_chunk) {\n",
        "            {\n",
        "                lock_guard<mutex> lock(mtx_fila);\n",
        "                fila_chunks.emplace(seq_id++, move(chunk));\n",
        "            }\n",
        "            cv_fila.notify_one();\n",
        "            chunk.clear();\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (!chunk.empty()) {\n",
        "        {\n",
        "            lock_guard<mutex> lock(mtx_fila);\n",
        "            fila_chunks.emplace(seq_id++, move(chunk));\n",
        "        }\n",
        "        cv_fila.notify_one();\n",
        "    }\n",
        "\n",
        "    leitura_concluida = true;\n",
        "    cv_fila.notify_all();\n",
        "    cv_resultado.notify_all();\n",
        "\n",
        "    for (auto& th : consumidores) th.join();\n",
        "    escritor.join();\n",
        "\n",
        "    entrada.close();\n",
        "    saida.close();\n",
        "}\n",
        "\n",
        "#endif // NORMALIZADOR_OMP_HPP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkncsfJ8rGoh",
        "outputId": "e7f378ee-73e9-41ce-f292-205890f0bdd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting main_omp.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile main_omp.cpp\n",
        "\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <string>\n",
        "#include <omp.h>\n",
        "#include <unordered_map>\n",
        "#include \"leitura.hpp\"\n",
        "#include \"sistema.hpp\"\n",
        "#include \"benchmark.hpp\"\n",
        "#include \"normalizador_omp.hpp\"\n",
        "\n",
        "constexpr const char* ARQUIVO_DATASET = \"dataset_00_sem_virg.csv\";\n",
        "\n",
        "int main() {\n",
        "    vector<string> nomeColunas;\n",
        "    vector<int> indicesAlvo;\n",
        "    vector<Linha> amostras;\n",
        "\n",
        "    double inicio = omp_get_wtime();\n",
        "\n",
        "    ler_cabecalho_e_amostras(ARQUIVO_DATASET, nomeColunas, amostras, 10);\n",
        "\n",
        "    detectar_colunas_categoricas(nomeColunas, amostras, indicesAlvo);\n",
        "\n",
        "    cout << \"Quantidade de colunas categoricas detectadas: \" << indicesAlvo.size() << endl;\n",
        "    cout << \"Colunas categoricas detectadas:\" << endl;\n",
        "    for (int indice : indicesAlvo) {\n",
        "        if (indice < nomeColunas.size()) {\n",
        "            cout << \"- \" << nomeColunas[indice] << endl;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    BenchmarkInfo info = coletar_info_benchmark(ARQUIVO_DATASET, amostras, indicesAlvo.size(), omp_get_max_threads());\n",
        "    info.linhas_por_chunk = calcular_linhas_por_chunk(info.ram_disponivel_mb, info.bytes_por_linha);\n",
        "    exibir_info_benchmark(info);\n",
        "\n",
        "    unordered_map<string, unordered_map<string, int>> mapas;\n",
        "    unordered_map<string, int> contadores;\n",
        "    construir_mapas_codificacao_por_chunks(ARQUIVO_DATASET, nomeColunas, indicesAlvo, info.linhas_por_chunk, mapas, contadores);\n",
        "\n",
        "    gerar_arquivos_id_por_coluna(mapas);\n",
        "    gerar_dataset_codificado(ARQUIVO_DATASET, nomeColunas, indicesAlvo, mapas, info.linhas_por_chunk);\n",
        "\n",
        "    double fim = omp_get_wtime();\n",
        "    info.tempo_execucao = fim - inicio;\n",
        "\n",
        "    salvar_info_benchmark_csv(info, \"benchmark_omp.csv\");\n",
        "\n",
        "    cout << \"Tempo de execucao: \" << info.tempo_execucao << \" segundos\" << endl;\n",
        "    cout << \"Tempo de execucao formatado: \" << formatar_tempo(info.tempo_execucao) << endl;\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrzfWEjYrapb",
        "outputId": "ad77a13a-2634-4bd6-bc54-588db3713cda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantidade de colunas categoricas detectadas: 12\n",
            "Colunas categoricas detectadas:\n",
            "- cdtup\n",
            "- berco\n",
            "- portoatracacao\n",
            "- mes\n",
            "- tipooperacao\n",
            "- tiponavegacaoatracacao\n",
            "- terminal\n",
            "- origem\n",
            "- destino\n",
            "- cdmercadoria\n",
            "- naturezacarga\n",
            "- sentido\n",
            "\n",
            "===== INFOS =====\n",
            "Nome do arquivo: dataset_00_sem_virg.csv\n",
            "Tamanho do arquivo: 2927 MB\n",
            "RAM disponivel: 6292 MB\n",
            "RAM total do sistema: 16330 MB\n",
            "Bytes por linha (estimado): 222\n",
            "Linhas por chunk: 1188763\n",
            "Tamnho por chunk: 251 MB\n",
            "Processador: AMD Ryzen 5 3600X 6-Core Processor             \n",
            "Cores (threads): 12\n",
            "Colunas categóricas detectadas: 12\n",
            "======================\n",
            "\n",
            "Tempo de execucao: 248.027 segundos\n",
            "Tempo de execucao formatado: 4m 8s\n"
          ]
        }
      ],
      "source": [
        "!g++ main_omp.cpp -fopenmp -std=c++17 -o main_omp.exe\n",
        "!main_omp && del main_omp.exe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwjSzuWt-KiC",
        "outputId": "c0249bd1-080a-4592-9810-98e7aa3964b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Movido: benchmark_omp.csv -> omp_csv/\n",
            "Movido: dataset_codificado_omp.csv -> omp_csv/\n",
            "Movido: ID_berco.csv -> omp_csv/\n",
            "Movido: ID_cdmercadoria.csv -> omp_csv/\n",
            "Movido: ID_cdtup.csv -> omp_csv/\n",
            "Movido: ID_destino.csv -> omp_csv/\n",
            "Movido: ID_mes.csv -> omp_csv/\n",
            "Movido: ID_naturezacarga.csv -> omp_csv/\n",
            "Movido: ID_origem.csv -> omp_csv/\n",
            "Movido: ID_portoatracacao.csv -> omp_csv/\n",
            "Movido: ID_sentido.csv -> omp_csv/\n",
            "Movido: ID_terminal.csv -> omp_csv/\n",
            "Movido: ID_tiponavegacaoatracacao.csv -> omp_csv/\n",
            "Movido: ID_tipooperacao.csv -> omp_csv/\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from glob import glob\n",
        "\n",
        "# 1. Criar pasta de destino\n",
        "destino = \"omp_csv\"\n",
        "os.makedirs(destino, exist_ok=True)\n",
        "\n",
        "# 2. Identificar arquivos CSV gerados\n",
        "csvs = glob(\"*.csv\")\n",
        "csvs = [f for f in csvs if f.startswith(\"ID_\") or f in (\"dataset_codificado_omp.csv\", \"benchmark_omp.csv\")]\n",
        "\n",
        "# 3. Mover para pasta\n",
        "for arquivo in csvs:\n",
        "    shutil.move(arquivo, os.path.join(destino, arquivo))\n",
        "    print(f\"Movido: {arquivo} -> {destino}/\")\n",
        "\n",
        "if not csvs:\n",
        "    print(\"Nenhum arquivo .csv correspondente encontrado.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6smZhzUiKGJ"
      },
      "source": [
        "# Executar Threads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXztKl9_hhqy",
        "outputId": "a9449711-150b-47c6-bbbb-f02b32590507"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting normalizacao_threads.hpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile normalizacao_threads.hpp\n",
        "\n",
        "#ifndef NORMALIZACAO_THREADS_HPP\n",
        "#define NORMALIZACAO_THREADS_HPP\n",
        "\n",
        "#include <vector>\n",
        "#include <string>\n",
        "#include <unordered_map>\n",
        "#include <unordered_set>\n",
        "#include <fstream>\n",
        "#include <sstream>\n",
        "#include <memory>\n",
        "#include <mutex>\n",
        "#include <condition_variable>\n",
        "#include <atomic>\n",
        "#include <map>\n",
        "#include <thread>\n",
        "#include <queue>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "using Linha = vector<string>;\n",
        "\n",
        "\n",
        "inline void construir_mapas_codificacao_por_chunks(const string& caminho,\n",
        "                                                   const vector<string>& nomeColunas,\n",
        "                                                   const vector<int>& indicesAlvo,\n",
        "                                                   size_t linhas_por_chunk,\n",
        "                                                   unordered_map<string, unordered_map<string, int>>& mapas,\n",
        "                                                   unordered_map<string, int>& contadores) {\n",
        "    ifstream arquivo(caminho);\n",
        "    if (!arquivo.is_open()) {\n",
        "        cerr << \"Erro ao abrir o arquivo para processar chunks.\" << endl;\n",
        "        exit(1);\n",
        "    }\n",
        "\n",
        "    string cabecalho;\n",
        "    getline(arquivo, cabecalho); // descarta cabeçalho\n",
        "\n",
        "    string linha;\n",
        "    vector<Linha> chunk;\n",
        "    mutex mtx;\n",
        "\n",
        "    auto processar_chunk = [&](const vector<Linha>& chunk_local) {\n",
        "        unsigned n_threads = thread::hardware_concurrency();\n",
        "        if (n_threads == 0) n_threads = 2;\n",
        "\n",
        "        vector<unordered_map<string, unordered_map<string, int>>> mapasLocais(n_threads);\n",
        "        vector<thread> threads;\n",
        "\n",
        "        for (unsigned tid = 0; tid < n_threads; ++tid) {\n",
        "            threads.emplace_back([&, tid]() {\n",
        "                for (size_t i = tid; i < indicesAlvo.size(); i += n_threads) {\n",
        "                    int col = indicesAlvo[i];\n",
        "                    string nomeCol = nomeColunas[col];\n",
        "                    for (const auto& linhaChunk : chunk_local) {\n",
        "                        if (col >= linhaChunk.size()) continue;\n",
        "                        string valor = linhaChunk[col];\n",
        "                        if (valor.empty()) continue;\n",
        "                        mapasLocais[tid][nomeCol][valor];\n",
        "                    }\n",
        "                }\n",
        "            });\n",
        "        }\n",
        "\n",
        "        for (auto& t : threads) t.join();\n",
        "\n",
        "        lock_guard<mutex> lock(mtx);\n",
        "        for (const auto& local : mapasLocais) {\n",
        "            for (const auto& [coluna, mapa] : local) {\n",
        "                for (const auto& [valor, _] : mapa) {\n",
        "                    if (mapas[coluna].find(valor) == mapas[coluna].end()) {\n",
        "                        mapas[coluna][valor] = contadores[coluna]++;\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    };\n",
        "\n",
        "    while (getline(arquivo, linha)) {\n",
        "        stringstream ss(linha);\n",
        "        string valor;\n",
        "        Linha linhaDados;\n",
        "        while (getline(ss, valor, ',')) {\n",
        "            linhaDados.push_back(valor);\n",
        "        }\n",
        "        chunk.push_back(linhaDados);\n",
        "\n",
        "        if (chunk.size() >= linhas_por_chunk) {\n",
        "            processar_chunk(chunk);\n",
        "            chunk.clear();\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (!chunk.empty()) {\n",
        "        processar_chunk(chunk);\n",
        "    }\n",
        "\n",
        "    arquivo.close();\n",
        "}\n",
        "\n",
        "inline void gerar_arquivos_id_por_coluna(const unordered_map<string, unordered_map<string, int>>& mapas) {\n",
        "    unsigned n_threads = thread::hardware_concurrency();\n",
        "    if (n_threads == 0) n_threads = 2;\n",
        "\n",
        "    vector<thread> threads;\n",
        "    mutex mtx_erro;\n",
        "\n",
        "    vector<string> chaves;\n",
        "    for (const auto& [coluna, _] : mapas) {\n",
        "        chaves.push_back(coluna);\n",
        "    }\n",
        "\n",
        "    auto worker = [&](unsigned tid) {\n",
        "        for (size_t i = tid; i < chaves.size(); i += n_threads) {\n",
        "            const string& nomeCol = chaves[i];\n",
        "            const auto& mapa = mapas.at(nomeCol);\n",
        "\n",
        "            ofstream arquivo(\"ID_\" + nomeCol + \".csv\");\n",
        "            if (!arquivo.is_open()) {\n",
        "                lock_guard<mutex> lock(mtx_erro);\n",
        "                cerr << \"Erro ao criar arquivo ID_\" << nomeCol << \".csv\" << endl;\n",
        "                continue;\n",
        "            }\n",
        "\n",
        "            arquivo << \"COD,CONTEUDO\\n\";\n",
        "            for (const auto& [conteudo, cod] : mapa) {\n",
        "                arquivo << cod << \",\" << conteudo << \"\\n\";\n",
        "            }\n",
        "\n",
        "            arquivo.close();\n",
        "        }\n",
        "    };\n",
        "\n",
        "    for (unsigned tid = 0; tid < n_threads; ++tid) {\n",
        "        threads.emplace_back(worker, tid);\n",
        "    }\n",
        "\n",
        "    for (auto& t : threads) t.join();\n",
        "}\n",
        "\n",
        "inline vector<string> codificar_linhas_chunk(const vector<string>& chunk,\n",
        "                                             const vector<string>& nomeColunas,\n",
        "                                             const unordered_map<string, unordered_map<string, int>>& mapas) {\n",
        "    vector<string> linhasCodificadas(chunk.size());\n",
        "\n",
        "    unsigned n_threads = thread::hardware_concurrency();\n",
        "    if (n_threads == 0) n_threads = 2;\n",
        "    vector<thread> threads;\n",
        "\n",
        "    size_t linhas_por_thread = (chunk.size() + n_threads - 1) / n_threads;\n",
        "\n",
        "    for (unsigned tid = 0; tid < n_threads; ++tid) {\n",
        "        threads.emplace_back([&, tid]() {\n",
        "            size_t inicio = tid * linhas_por_thread;\n",
        "            size_t fim = min(inicio + linhas_por_thread, chunk.size());\n",
        "\n",
        "            for (size_t i = inicio; i < fim; ++i) {\n",
        "                stringstream ss(chunk[i]);\n",
        "                string valor;\n",
        "                vector<string> campos;\n",
        "                while (getline(ss, valor, ',')) {\n",
        "                    campos.push_back(valor);\n",
        "                }\n",
        "\n",
        "                stringstream codificada;\n",
        "                for (size_t j = 0; j < campos.size(); j++) {\n",
        "                    const string& nomeCol = nomeColunas[j];\n",
        "                    if (mapas.count(nomeCol)) {\n",
        "                        codificada << mapas.at(nomeCol).at(campos[j]);\n",
        "                    } else {\n",
        "                        codificada << campos[j];\n",
        "                    }\n",
        "                    if (j < campos.size() - 1) codificada << \",\";\n",
        "                }\n",
        "\n",
        "                linhasCodificadas[i] = codificada.str();\n",
        "            }\n",
        "        });\n",
        "    }\n",
        "\n",
        "    for (auto& t : threads) t.join();\n",
        "\n",
        "    return linhasCodificadas;\n",
        "}\n",
        "\n",
        "inline void gerar_dataset_codificado(const string& caminho,\n",
        "                                     const vector<string>& nomeColunas,\n",
        "                                     const vector<int>& indicesAlvo,\n",
        "                                     const unordered_map<string, unordered_map<string, int>>& mapas,\n",
        "                                     size_t linhas_por_chunk) {\n",
        "    ifstream entrada(caminho);\n",
        "    ofstream saida(\"dataset_codificado_th.csv\");\n",
        "\n",
        "    if (!entrada.is_open() || !saida.is_open()) {\n",
        "        cerr << \"Erro ao abrir arquivos.\" << endl;\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    string cabecalho;\n",
        "    getline(entrada, cabecalho);\n",
        "    saida << cabecalho << \"\\n\";\n",
        "\n",
        "    queue<pair<size_t, vector<string>>> fila_chunks;\n",
        "    map<size_t, vector<string>> resultados;\n",
        "\n",
        "    mutex mtx_fila, mtx_resultado;\n",
        "    condition_variable cv_fila, cv_resultado;\n",
        "    atomic<bool> leitura_concluida{false};\n",
        "\n",
        "    size_t seq_id = 0;\n",
        "    const unsigned N_CONSUMIDORES = thread::hardware_concurrency();\n",
        "    vector<thread> consumidores;\n",
        "\n",
        "    // CONSUMIDORES\n",
        "    for (unsigned t = 0; t < N_CONSUMIDORES; ++t) {\n",
        "        consumidores.emplace_back([&]() {\n",
        "            while (true) {\n",
        "                pair<size_t, vector<string>> item;\n",
        "\n",
        "                {\n",
        "                    unique_lock<mutex> lock(mtx_fila);\n",
        "                    cv_fila.wait(lock, [&]() {\n",
        "                        return !fila_chunks.empty() || leitura_concluida;\n",
        "                    });\n",
        "\n",
        "                    if (!fila_chunks.empty()) {\n",
        "                        item = move(fila_chunks.front());\n",
        "                        fila_chunks.pop();\n",
        "                    } else if (leitura_concluida) {\n",
        "                        break;\n",
        "                    } else {\n",
        "                        continue;\n",
        "                    }\n",
        "                }\n",
        "\n",
        "                auto codificadas = codificar_linhas_chunk(item.second, nomeColunas, mapas);\n",
        "\n",
        "                {\n",
        "                    lock_guard<mutex> lock(mtx_resultado);\n",
        "                    resultados[item.first] = move(codificadas);\n",
        "                }\n",
        "\n",
        "                cv_resultado.notify_one();\n",
        "            }\n",
        "        });\n",
        "    }\n",
        "\n",
        "    // ESCRITOR\n",
        "    thread escritor([&]() {\n",
        "        size_t proximo_seq = 0;\n",
        "\n",
        "        while (true) {\n",
        "            vector<string> linhas;\n",
        "            {\n",
        "                unique_lock<mutex> lock(mtx_resultado);\n",
        "                cv_resultado.wait(lock, [&]() {\n",
        "                    return resultados.count(proximo_seq) || (leitura_concluida && resultados.empty());\n",
        "                });\n",
        "\n",
        "                if (resultados.count(proximo_seq)) {\n",
        "                    linhas = move(resultados[proximo_seq]);\n",
        "                    resultados.erase(proximo_seq);\n",
        "                    ++proximo_seq;\n",
        "                } else if (leitura_concluida && resultados.empty()) {\n",
        "                    break;\n",
        "                } else {\n",
        "                    continue;\n",
        "                }\n",
        "            }\n",
        "\n",
        "            for (const auto& linha : linhas) {\n",
        "                saida << linha << \"\\n\";\n",
        "            }\n",
        "        }\n",
        "    });\n",
        "\n",
        "    // PRODUTOR (leitura do arquivo)\n",
        "    string linha;\n",
        "    vector<string> chunk;\n",
        "    while (getline(entrada, linha)) {\n",
        "        chunk.push_back(linha);\n",
        "        if (chunk.size() >= linhas_por_chunk) {\n",
        "            {\n",
        "                lock_guard<mutex> lock(mtx_fila);\n",
        "                fila_chunks.emplace(seq_id++, move(chunk));\n",
        "            }\n",
        "            cv_fila.notify_one();\n",
        "            chunk.clear();\n",
        "        }\n",
        "    }\n",
        "\n",
        "    if (!chunk.empty()) {\n",
        "        {\n",
        "            lock_guard<mutex> lock(mtx_fila);\n",
        "            fila_chunks.emplace(seq_id++, move(chunk));\n",
        "        }\n",
        "        cv_fila.notify_one();\n",
        "    }\n",
        "\n",
        "    leitura_concluida = true;\n",
        "    cv_fila.notify_all();\n",
        "    cv_resultado.notify_all();\n",
        "\n",
        "    for (auto& th : consumidores) th.join();\n",
        "    escritor.join();\n",
        "\n",
        "    entrada.close();\n",
        "    saida.close();\n",
        "}\n",
        "\n",
        "#endif // NORMALIZACAO_THREADS_HPP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkxQ9EPdiMee",
        "outputId": "1d3795aa-97ec-4d35-902a-d8ee75a759e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting main_threads.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile main_threads.cpp\n",
        "\n",
        "#include <iostream>\n",
        "#include <vector>\n",
        "#include <string>\n",
        "#include <omp.h>\n",
        "#include <unordered_map>\n",
        "#include \"leitura.hpp\"\n",
        "#include \"benchmark.hpp\"\n",
        "#include \"normalizacao_threads.hpp\"\n",
        "\n",
        "constexpr const char* ARQUIVO_DATASET = \"dataset_00_sem_virg.csv\";\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "int main() {\n",
        "    vector<string> nomeColunas;\n",
        "    vector<int> indicesAlvo;\n",
        "    vector<Linha> amostras;\n",
        "    int linhas_amostra = 10;\n",
        "\n",
        "    double inicio = omp_get_wtime();\n",
        "\n",
        "    ler_cabecalho_e_amostras(ARQUIVO_DATASET, nomeColunas, amostras, linhas_amostra);\n",
        "    \n",
        "    detectar_colunas_categoricas(nomeColunas, amostras, indicesAlvo);\n",
        "\n",
        "    cout << \"Quantidade de colunas categoricas detectadas: \" << indicesAlvo.size() << endl;\n",
        "    cout << \"Colunas categoricas detectadas:\" << endl;\n",
        "    for (int indice : indicesAlvo) {\n",
        "        if (indice < nomeColunas.size()) {\n",
        "            cout << \"- \" << nomeColunas[indice] << endl;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    BenchmarkInfo info = coletar_info_benchmark(ARQUIVO_DATASET, amostras, indicesAlvo.size(), thread::hardware_concurrency());\n",
        "    info.linhas_por_chunk = calcular_linhas_por_chunk(info.ram_disponivel_mb, info.bytes_por_linha);\n",
        "    exibir_info_benchmark(info);\n",
        "\n",
        "    unordered_map<string, unordered_map<string, int>> mapas;\n",
        "    unordered_map<string, int> contadores;\n",
        "    construir_mapas_codificacao_por_chunks(ARQUIVO_DATASET, nomeColunas, indicesAlvo, info.linhas_por_chunk, mapas, contadores);\n",
        "\n",
        "    gerar_arquivos_id_por_coluna(mapas);\n",
        "    gerar_dataset_codificado(ARQUIVO_DATASET, nomeColunas, indicesAlvo, mapas, info.linhas_por_chunk);\n",
        "\n",
        "    double fim = omp_get_wtime();\n",
        "    info.tempo_execucao = fim - inicio;\n",
        "\n",
        "    cout << \"Tempo de execucao: \" << info.tempo_execucao << \" segundos\" << endl;\n",
        "    cout << \"Tempo de execucao formatado: \" << formatar_tempo(info.tempo_execucao) << endl;\n",
        "    \n",
        "    salvar_info_benchmark_csv(info, \"benchmark_threads.csv\");\n",
        "    \n",
        "    return 0;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB-CxF4sLg86",
        "outputId": "81189c16-33e5-47db-c1df-5273fd52b5ae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "In file included from main_threads.cpp:9:\n",
            "normalizacao_threads.hpp: In function 'void gerar_dataset_codificado(const string&, const std::vector<std::__cxx11::basic_string<char> >&, const std::vector<int>&, const std::unordered_map<std::__cxx11::basic_string<char>, std::unordered_map<std::__cxx11::basic_string<char>, int> >&, size_t)':\n",
            "normalizacao_threads.hpp:202:5: error: 'queue' was not declared in this scope\n",
            "     queue<pair<size_t, vector<string>>> fila_chunks;\n",
            "     ^~~~~\n",
            "normalizacao_threads.hpp:202:5: note: 'std::queue' is defined in header '<queue>'; did you forget to '#include <queue>'?\n",
            "normalizacao_threads.hpp:17:1:\n",
            "+#include <queue>\n",
            " \n",
            "normalizacao_threads.hpp:202:5:\n",
            "     queue<pair<size_t, vector<string>>> fila_chunks;\n",
            "     ^~~~~\n",
            "normalizacao_threads.hpp:202:39: error: expected primary-expression before '>' token\n",
            "     queue<pair<size_t, vector<string>>> fila_chunks;\n",
            "                                       ^\n",
            "normalizacao_threads.hpp:202:41: error: 'fila_chunks' was not declared in this scope\n",
            "     queue<pair<size_t, vector<string>>> fila_chunks;\n",
            "                                         ^~~~~~~~~~~\n",
            "In file included from normalizacao_threads.hpp:13,\n",
            "                 from main_threads.cpp:9:\n",
            "C:/Program Files/CodeBlocks/MinGW/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/condition_variable: In instantiation of 'void std::condition_variable::wait(std::unique_lock<std::mutex>&, _Predicate) [with _Predicate = gerar_dataset_codificado(const string&, const std::vector<std::__cxx11::basic_string<char> >&, const std::vector<int>&, const std::unordered_map<std::__cxx11::basic_string<char>, std::unordered_map<std::__cxx11::basic_string<char>, int> >&, size_t)::<lambda()>::<lambda()>]':\n",
            "normalizacao_threads.hpp:223:22:   required from here\n",
            "C:/Program Files/CodeBlocks/MinGW/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/condition_variable:98:13: error: could not convert '__p.gerar_dataset_codificado(const string&, const std::vector<std::__cxx11::basic_string<char> >&, const std::vector<int>&, const std::unordered_map<std::__cxx11::basic_string<char>, std::unordered_map<std::__cxx11::basic_string<char>, int> >&, size_t)::<lambda()>::<lambda()>()' from 'void' to 'bool'\n",
            "  while (!__p())\n",
            "          ~~~^~\n",
            "C:/Program Files/CodeBlocks/MinGW/lib/gcc/x86_64-w64-mingw32/8.1.0/include/c++/condition_variable:98:9: error: in argument to unary !\n",
            "  while (!__p())\n",
            "         ^~~~~~\n",
            "'main_th' n�o � reconhecido como um comando interno\n",
            "ou externo, um programa oper�vel ou um arquivo em lotes.\n"
          ]
        }
      ],
      "source": [
        "!g++ -std=c++17 main_threads.cpp -o main_th.exe -fopenmp\n",
        "!main_th && del main_th.exe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56IosXXz-dEt",
        "outputId": "31ff7255-bed2-4c88-9e0d-4c011f039f2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nenhum arquivo .csv correspondente encontrado.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from glob import glob\n",
        "\n",
        "# 1. Criar pasta de destino\n",
        "destino = \"thread_csv\"\n",
        "os.makedirs(destino, exist_ok=True)\n",
        "\n",
        "# 2. Identificar arquivos CSV gerados\n",
        "csvs = glob(\"*.csv\")\n",
        "csvs = [f for f in csvs if f.startswith(\"ID_\") or f in (\"dataset_codificado_th.csv\", \"benchmark_threads.csv\")]\n",
        "\n",
        "# 3. Mover para pasta\n",
        "for arquivo in csvs:\n",
        "    shutil.move(arquivo, os.path.join(destino, arquivo))\n",
        "    print(f\"Movido: {arquivo} -> {destino}/\")\n",
        "\n",
        "if not csvs:\n",
        "    print(\"Nenhum arquivo .csv correspondente encontrado.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPJV7IdmCVDc"
      },
      "source": [
        "# Comparação OMP x Threads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "pxXgCl1ACfJD",
        "outputId": "93cb543d-453e-462b-f8b7-e6ce93117cbe"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'thread_csv/benchmark_threads.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Carregar CSVs atualizados\u001b[39;00m\n\u001b[32m     17\u001b[39m df_omp = pd.read_csv(\u001b[33m\"\u001b[39m\u001b[33momp_csv/benchmark_omp.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m df_thread = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthread_csv/benchmark_threads.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Marcar a origem\u001b[39;00m\n\u001b[32m     21\u001b[39m df_omp[\u001b[33m\"\u001b[39m\u001b[33mTipo\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mOMP\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'thread_csv/benchmark_threads.csv'"
          ]
        }
      ],
      "source": [
        "# Ensure pandas and Jinja2 are installed\n",
        "try:\n",
        "    import pandas as pd\n",
        "except ModuleNotFoundError:\n",
        "    import os\n",
        "    os.system(\"pip install pandas\")\n",
        "    import pandas as pd\n",
        "\n",
        "try:\n",
        "    import jinja2\n",
        "except ModuleNotFoundError:\n",
        "    import os\n",
        "    os.system(\"pip install Jinja2\")\n",
        "    import jinja2\n",
        "\n",
        "# Carregar CSVs atualizados\n",
        "df_omp = pd.read_csv(\"omp_csv/benchmark_omp.csv\")\n",
        "df_thread = pd.read_csv(\"thread_csv/benchmark_threads.csv\")\n",
        "\n",
        "# Marcar a origem\n",
        "df_omp[\"Tipo\"] = \"OMP\"\n",
        "df_thread[\"Tipo\"] = \"Threads\"\n",
        "\n",
        "# Unir\n",
        "df = pd.concat([df_omp, df_thread], ignore_index=True)\n",
        "\n",
        "# Renomear colunas para apresentação\n",
        "df = df.rename(columns={\n",
        "    \"Tipo\": \"Tipo\",\n",
        "    \"nome_arquivo\": \"Arquivo\",\n",
        "    \"nome_cpu\": \"CPU\",\n",
        "    \"num_threads\": \"Threads\",\n",
        "    \"ram_total_mb\": \"RAM Total\",\n",
        "    \"ram_disponivel_mb\": \"RAM Disponível\",\n",
        "    \"tamanho_arq_mb\": \"Tamanho Arquivo\",\n",
        "    \"bytes_por_linha\": \"Bytes por Linha\",\n",
        "    \"linhas_por_chunk\": \"Linhas por Chunk\",\n",
        "    \"tamanho_chunk_mb\": \"Tamanho do Chunk (MB)\",\n",
        "    \"total_col_categoricas\": \"Colunas Categóricas\",\n",
        "    \"tempo_execucao_segundos\": \"Tempo (s)\",\n",
        "    \"tempo_formatado\": \"Tempo Formatado\",\n",
        "})\n",
        "\n",
        "# Ordenar colunas com Tipo no início\n",
        "colunas = [\n",
        "    \"Tipo\", \"Arquivo\", \"CPU\", \"Threads\",\n",
        "    \"RAM Total\", \"RAM Disponível\", \"Tamanho Arquivo\",\n",
        "    \"Bytes por Linha\", \"Linhas por Chunk\", \"Tamanho do Chunk (MB)\",\n",
        "    \"Colunas Categóricas\", \"Tempo (s)\", \"Tempo Formatado\"\n",
        "]\n",
        "df = df[colunas]\n",
        "\n",
        "# Formatando colunas com MB\n",
        "for col in [\"RAM Total\", \"RAM Disponível\", \"Tamanho Arquivo\", \"Tamanho do Chunk (MB)\"]:\n",
        "    df[col] = df[col].map(lambda x: f\"{x:.0f} MB\" if \"Chunk\" not in col else f\"{x:.2f} MB\")\n",
        "\n",
        "# Mostrar com estilo\n",
        "df.style.set_caption(\"Benchmark Comparativo: OMP vs Threads\") \\\n",
        "    .set_table_attributes(\"style='display:inline'\") \\\n",
        "    .format({\n",
        "        \"Bytes por Linha\": \"{:,}\",\n",
        "        \"Linhas por Chunk\": \"{:,}\",\n",
        "        \"Colunas Categóricas\": \"{}\",\n",
        "        \"Tempo (s)\": \"{:.2f} s\"\n",
        "    })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmqMpRvR3u7y"
      },
      "source": [
        "# Desafios\n",
        "\n",
        "* Leitura eficiente de grandes arquivos CSV\n",
        "  - Arquivos com milhões de linhas não podem ser carregados inteiramente na RAM.\n",
        "  - Solução: leitura por chunks, baseada em estimativa da memória disponível e do tamanho médio por linha.\n",
        "* Detecção automática de colunas categóricas\n",
        "  - Precisava distinguir colunas numéricas de categóricas de forma dinâmica.\n",
        "  - Solução: análise das 5 primeiras linhas e exclusão de campos nulos e numéricos.\n",
        "* Normalização categórica com paralelismo\n",
        "  - Codificação de valores únicos por coluna sem travamento entre threads.\n",
        "  - Solução: uso de mapas locais dentro de cada thread durante a contagem de valores por coluna, seguido por um bloco #pragma omp critical apenas no momento da fusão dos dados no mapa global."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNnt6lRj4sfI"
      },
      "source": [
        "# Possíveis Melhorias\n",
        "\n",
        "* Evitar a alocação dinâmica excessiva das bibliotecas padrão do C++ adotando buffers pré-alocados e estruturas otimizadas para uso intensivo de memória.\n",
        "* Monitoramento do uso de memória RAM durante a execução do programa"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "oYNnYAWMKlRJ",
        "VhEe9KI2KphG"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
